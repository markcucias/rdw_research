Metadata-Version: 2.4
Name: rdw
Version: 0.1.0
Summary: Self Driving Challenge perception algorithms
Requires-Python: >=3.12
Description-Content-Type: text/markdown
Requires-Dist: numpy>=2.3.4
Requires-Dist: onnxruntime>=1.23.2
Requires-Dist: opencv-python>=4.11.0.86
Requires-Dist: pyyaml>=6.0.3
Requires-Dist: typer>=0.20.0

# RDW – Self Driving Challenge Perception

This project is the software environment for testing and developing CPU-only perception pipelines for the **RDW Self Driving Challenge**.  
It focuses on three modular algorithms:
1. **Classical + Neural Prior Fusion** — HSV/Canny/Hough lane detection guided by a RoadNet-Lite drivable-area mask.  
2. **Motion-Aware Neural Fusion** — LaneNet segmentation fused with monocular odometry via Kalman/Particle filters.  
3. **Ultra-Fast Row-Anchor Segmentation** — Ultra-Fast Lane Detection combined with RoadNet attention and optical-flow smoothing.

Each algorithm is an independent, runnable component on the vehicle’s CPU.

---

## Setup (once per machine)

Install [uv](https://github.com/astral-sh/uv) if you don’t have it yet:
```bash
pip install uv
```

Install dependencies and create virtual environment
```bash
uv init
uv sync
```

## Run the Classical + Neural Prior Algorithm

Single image:
```bash
uv run rdw-classical data/6.png
uv run motion_fusion data/6.png --display
```

Folder of images:
```bash
uv run rdw-classical data/frames_2024
```

Camera:
```bash
uv run rdw-classical camera:0 --display
```
